{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import wandb\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        self.paths_a = glob('./data/trainA/*.jpg')\n",
    "        self.paths_b = glob('./data/trainB/*.jpg')\n",
    "\n",
    "        self.imgs_a = np.zeros(\n",
    "            (len(self.paths_a), 32, 32, 3), dtype=np.float32)\n",
    "        for i, path in tqdm(enumerate(self.paths_a)):\n",
    "            img = np.asarray(Image.open(path)) / 255.0\n",
    "            img = cv2.resize(img, dsize=(\n",
    "                32, 32), interpolation=cv2.INTER_CUBIC).reshape(1, 32, 32, 3)\n",
    "            self.imgs_a[i] = img\n",
    "\n",
    "        self.imgs_b = np.zeros(\n",
    "            (len(self.paths_b), 32, 32, 3), dtype=np.float32)\n",
    "        for i, path in tqdm(enumerate(self.paths_b)):\n",
    "            img = np.asarray(Image.open(path)) / 255.0\n",
    "            img = cv2.resize(img, dsize=(\n",
    "                32, 32), interpolation=cv2.INTER_CUBIC).reshape(1, 32, 32, 3)\n",
    "            self.imgs_b[i] = img\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(hue=0.15),\n",
    "            transforms.RandomGrayscale(p=0.25),\n",
    "            transforms.RandomRotation(35),\n",
    "            transforms.RandomPerspective(distortion_scale=0.35),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths_a)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_a = self.imgs_a[index]\n",
    "        img_b = self.imgs_b[index]\n",
    "\n",
    "        img_a = self.transforms(img_a).numpy().transpose(1, 2, 0)\n",
    "        img_b = self.transforms(img_b).numpy().transpose(1, 2, 0)\n",
    "        # img_a = img_a.transpose(1, 2, 0)\n",
    "        # img_b = img_b.transpose(1, 2, 0)\n",
    "\n",
    "        return img_a, img_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard(xs):\n",
    "    return jax.tree_map(\n",
    "        lambda x: x.reshape((jax.device_count(), -1) + x.shape[1:]), xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IN(nn.Module):\n",
    "    def __call__(self, x):\n",
    "        # assuming an image in the format HxWxC\n",
    "        mu = jnp.mean(x, axis=(1, 2), keepdims=True)\n",
    "        sigma_2 = jnp.var(x, axis=(1, 2), keepdims=True)\n",
    "\n",
    "        return (x - mu) / jnp.sqrt(sigma_2 + 1e-5)\n",
    "\n",
    "\n",
    "class AdaIN(nn.Module):\n",
    "    @nn.compact\n",
    "    # assuming an image in the format HxWxC\n",
    "    def __call__(self, content, style_mean, style_var):\n",
    "        content_mu = jnp.mean(content, axis=(1, 2), keepdims=True)\n",
    "        content_sigma_2 = jnp.var(content, axis=(1, 2), keepdims=True)\n",
    "\n",
    "        normalized_content = (content - content_mu) / \\\n",
    "            jnp.sqrt(content_sigma_2 + 1e-5)\n",
    "\n",
    "        return normalized_content * jnp.sqrt(style_var + 1e-5) + style_mean\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    padding: int\n",
    "    features: int\n",
    "    kernel_size: int\n",
    "    strides: int\n",
    "    norm: str = \"none\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, means=None, variances=None):\n",
    "        x = jnp.pad(x, [(0, 0), (self.padding, self.padding),\n",
    "                        (self.padding, self.padding), (0, 0)], mode='constant')\n",
    "\n",
    "        if self.norm == \"IN\":\n",
    "            x = IN()(x)\n",
    "        # elif self.norm == 'AdaIN' and means is not None and variances is not None:\n",
    "        #     x = AdaIN()(x, means, variances)\n",
    "\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=self.features, kernel_size=(self.kernel_size, self.kernel_size),\n",
    "                    strides=(self.strides, self.strides), padding='VALID')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    padding: int\n",
    "    features: int\n",
    "    kernel_size: int\n",
    "    strides: int\n",
    "    norm: str = \"none\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, means=None, variances=None):\n",
    "        residual_branch = x\n",
    "\n",
    "        x = Block(self.padding, self.features,\n",
    "                  self.kernel_size, self.strides, self.norm)(x, means, variances)\n",
    "        x = Block(self.padding, self.features,\n",
    "                  self.kernel_size, self.strides, \"none\")(x, means, variances)\n",
    "\n",
    "        return x + residual_branch\n",
    "\n",
    "\n",
    "class StyleEncoder(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = Block(padding=3, features=64, kernel_size=7, strides=1)(x)\n",
    "\n",
    "        x = Block(padding=1, features=64*2, kernel_size=4, strides=2)(x)\n",
    "        x = Block(padding=1, features=64*2*2,\n",
    "                  kernel_size=4, strides=2)(x)\n",
    "\n",
    "        x = Block(padding=1, features=64*2*2,\n",
    "                  kernel_size=4, strides=2)(x)\n",
    "        x = Block(padding=1, features=64*2*2,\n",
    "                  kernel_size=4, strides=2)(x)\n",
    "\n",
    "        x = jnp.mean(x, axis=(1, 2), keepdims=True)\n",
    "        x = nn.Conv(features=8, kernel_size=(1, 1),\n",
    "                    strides=(1, 1), padding='VALID')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ContentEncoder(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "\n",
    "        x = Block(padding=3, features=64, kernel_size=7,\n",
    "                  strides=1, norm='IN')(x)\n",
    "\n",
    "        x = Block(padding=1, features=64*2,\n",
    "                  kernel_size=4, strides=2, norm='IN')(x)\n",
    "        x = Block(padding=1, features=64*2*2,\n",
    "                  kernel_size=4, strides=2, norm='IN')(x)\n",
    "\n",
    "        x = ResBlock(\n",
    "            padding=1, features=64*2*2, kernel_size=3, strides=1, norm='IN')(x)\n",
    "        x = ResBlock(\n",
    "            padding=1, features=64*2*2, kernel_size=3, strides=1, norm='IN')(x)\n",
    "        x = ResBlock(\n",
    "            padding=1, features=64*2*2, kernel_size=3, strides=1, norm='IN')(x)\n",
    "        x = ResBlock(\n",
    "            padding=1, features=64*2*2, kernel_size=3, strides=1, norm='IN')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=256, use_bias=True)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256, use_bias=True)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256, use_bias=True)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256, use_bias=True)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=4*256*2, use_bias=True)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x, AdaIN_params):\n",
    "\n",
    "        means = []\n",
    "        variances = []\n",
    "        for i in range(0, 4*256*2, 256*2):\n",
    "            means_variances = AdaIN_params[:, :, :, i:i+256*2]\n",
    "            means.append(means_variances[:, :, :, :256])\n",
    "            variances.append(means_variances[:, :, :, 256:])\n",
    "        \n",
    "        x = ResBlock(padding=1, features=64*2*2, kernel_size=3,\n",
    "                     strides=1, norm='AdaIN')(x, means[0], variances[0])\n",
    "        x = ResBlock(padding=1, features=64*2*2, kernel_size=3,\n",
    "                     strides=1, norm='')(x, means[1], variances[1])\n",
    "        x = ResBlock(padding=1, features=64*2*2, kernel_size=3,\n",
    "                     strides=1, norm='')(x, means[2], variances[2])\n",
    "        x = ResBlock(padding=1, features=64*2*2, kernel_size=3,\n",
    "                     strides=1, norm='')(x, means[3], variances[3])\n",
    "\n",
    "        x = jax.image.resize(\n",
    "            x, (x.shape[0], x.shape[1]*2, x.shape[2]*2, x.shape[3]), method=jax.image.ResizeMethod.NEAREST)\n",
    "        x = Block(padding=2, features=64*2, kernel_size=5,\n",
    "                  strides=1, norm='IN')(x)\n",
    "\n",
    "        x = jax.image.resize(\n",
    "            x, (x.shape[0], x.shape[1]*2, x.shape[2]*2, x.shape[3]), method=jax.image.ResizeMethod.NEAREST)\n",
    "        x = Block(padding=2, features=64, kernel_size=5,\n",
    "                  strides=1, norm='IN')(x)\n",
    "\n",
    "        x = Block(padding=3, features=3, kernel_size=7, strides=1)(x)\n",
    "        x = jnp.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class G_enc(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        content = ContentEncoder()(x)\n",
    "        style = StyleEncoder()(x)\n",
    "        \n",
    "        return content, style\n",
    "\n",
    "class G_dec(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x, style):\n",
    "        AdaIN_params = MLP()(style)\n",
    "        out = Decoder()(x, AdaIN_params)\n",
    "        return out\n",
    "\n",
    "class D_part(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = jnp.pad(x, [(0, 0), (1, 1), (1, 1), (0, 0)], mode='constant')\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "        x = nn.Conv(features=64, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='VALID')(x)\n",
    "\n",
    "        x = jnp.pad(x, [(0, 0), (1, 1), (1, 1), (0, 0)], mode='constant')\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "        x = nn.Conv(features=64*2, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='VALID')(x)\n",
    "\n",
    "        x = jnp.pad(x, [(0, 0), (1, 1), (1, 1), (0, 0)], mode='constant')\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "        x = nn.Conv(features=64*2*2, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='VALID')(x)\n",
    "\n",
    "        x = jnp.pad(x, [(0, 0), (1, 1), (1, 1), (0, 0)], mode='constant')\n",
    "        x = nn.leaky_relu(x, negative_slope=0.2)\n",
    "        x = nn.Conv(features=64*2*2*2, kernel_size=(4, 4),\n",
    "                    strides=(2, 2), padding='VALID')(x)\n",
    "\n",
    "        x = nn.Conv(features=1, kernel_size=(1, 1),\n",
    "                    strides=(1, 1), padding=\"VALID\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class D(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "\n",
    "        out = D_part()(x)\n",
    "        outputs.append(out)\n",
    "\n",
    "        x = nn.avg_pool(x, window_shape=(3, 3), strides=(\n",
    "            2, 2), padding=((1, 1), (1, 1)))\n",
    "        out = D_part()(x)\n",
    "        outputs.append(out)\n",
    "\n",
    "        x = nn.avg_pool(x, window_shape=(3, 3), strides=(\n",
    "            2, 2), padding=((1, 1), (1, 1)))\n",
    "        out = D_part()(x)\n",
    "        outputs.append(out)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "init_x = jnp.ones((1, 64, 64, 3), jnp.float32)\n",
    "init_encoded = jnp.ones((1, 16, 16, 256), jnp.float32)\n",
    "init_z = jnp.zeros((1, 1, 1, 8), jnp.float32)\n",
    "init_x_acl = jnp.ones((1, 64, 64, 6), jnp.float32)\n",
    "\n",
    "variables_g_s_enc = G_enc().init(rng, init_x)\n",
    "variables_g_s_dec = G_dec().init(rng, init_encoded, init_z)\n",
    "\n",
    "variables_g_t_enc = G_enc().init(rng, init_x)\n",
    "variables_g_t_dec = G_dec().init(rng, init_encoded, init_z)\n",
    "\n",
    "variables_d_s = D().init(rng, init_x)\n",
    "variables_d_t = D().init(rng, init_x)\n",
    "variables_d_hat = D().init(rng, init_x_acl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'g_s_enc': variables_g_s_enc['params'],\n",
    "    'g_s_dec': variables_g_s_dec['params'],\n",
    "    'g_t_enc': variables_g_t_enc['params'],\n",
    "    'g_t_dec': variables_g_t_dec['params'],\n",
    "    'd_s': variables_d_s['params'],\n",
    "    'd_t': variables_d_t['params'],\n",
    "    'd_hat': variables_d_hat['params'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = jnp.ones((1, 64, 64, 3), jnp.float32)\n",
    "x_t = jnp.ones((1, 64, 64, 3), jnp.float32)\n",
    "z_1 = jax.random.normal(rng, shape=(1, 1, 1, 8))\n",
    "z_2 = jax.random.normal(rng, shape=(1, 1, 1, 8))\n",
    "z_3 = jax.random.normal(rng, shape=(1, 1, 1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(logits, labels):\n",
    "    loss = 0\n",
    "    for i in range(3):\n",
    "        loss +=jnp.mean((logits[i]-labels[i])**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(logits, labels):\n",
    "    return jnp.mean(jnp.abs(logits - labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_g(x_s, x_t, rng, params):\n",
    "    rng, rng_1, rng_2, rng_3 = jax.random.split(rng, 4)\n",
    "\n",
    "    bs = x_s.shape[0]\n",
    "    z_1 = jax.random.normal(rng_1, shape=(bs, 1, 1, 8))\n",
    "    z_2 = jax.random.normal(rng_2, shape=(bs, 1, 1, 8))\n",
    "    z_3 = jax.random.normal(rng_3, shape=(bs, 1, 1, 8))\n",
    "\n",
    "    c_s, z_s = G_enc().apply({'params': params['g_s_enc']}, x_s)\n",
    "    fake_s = G_dec().apply({'params': params['g_s_dec']}, c_s, z_1)\n",
    "\n",
    "    c_t, z_t = G_enc().apply({'params': params['g_t_enc']}, x_s)\n",
    "    fake_t = G_dec().apply({'params': params['g_t_dec']}, c_t, z_2)\n",
    "\n",
    "    c_recon_s, z_recon_s = G_enc().apply(\n",
    "        {'params': params['g_s_enc']}, fake_t)\n",
    "    fake_recon_s = G_dec().apply(\n",
    "        {'params': params['g_s_dec']}, c_recon_s, z_3)\n",
    "\n",
    "    fake_idt_s = G_dec().apply(\n",
    "        {'params': params['g_s_dec']}, c_s, z_s)\n",
    "    fake_idt_t = G_dec().apply(\n",
    "        {'params': params['g_t_dec']}, c_t, z_t)\n",
    "\n",
    "    fake_logits_s = D().apply({'params': params['d_s']}, fake_s)\n",
    "    fake_logits_t = D().apply({'params': params['d_t']}, fake_t)\n",
    "\n",
    "    fake_logits_recon_s = D().apply(\n",
    "        {'params': params['d_s']}, fake_recon_s)\n",
    "\n",
    "    s_fake_s_logits = D().apply(\n",
    "        {'params': params['d_hat']}, jnp.concatenate([x_s, fake_s], axis=3))\n",
    "    s_fake_recon_s_logits = D().apply(\n",
    "        {'params': params['d_hat']}, jnp.concatenate([x_s, fake_recon_s], axis=3))\n",
    "\n",
    "    real_adv_labels = [jnp.ones_like(fake_logits_s[0]), jnp.ones_like(\n",
    "        fake_logits_s[1]), jnp.ones_like(fake_logits_s[2])]\n",
    "    real_acl_labels = [jnp.ones_like(s_fake_s_logits[0]), jnp.ones_like(\n",
    "        s_fake_s_logits[1]), jnp.ones_like(s_fake_s_logits[2])]\n",
    "    fake_acl_labels = [jnp.zeros_like(s_fake_s_logits[0]), jnp.zeros_like(\n",
    "        s_fake_s_logits[1]), jnp.zeros_like(s_fake_s_logits[2])]\n",
    "\n",
    "    loss_adv = l2_loss(fake_logits_t, real_adv_labels) + (l2_loss(fake_logits_s,\n",
    "                                                                  real_adv_labels) + l2_loss(fake_logits_recon_s, real_adv_labels)) / 2\n",
    "    loss_acl = l2_loss(s_fake_s_logits, real_acl_labels) + \\\n",
    "        l2_loss(s_fake_recon_s_logits, fake_acl_labels)\n",
    "    loss_idt = l1_loss(x_s, fake_idt_s) + l1_loss(x_t, fake_idt_t)\n",
    "\n",
    "    loss = loss_adv + 0.5 * loss_acl + loss_idt\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = loss_g(x_s, x_t, rng, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_d(x_s, x_t, rng, params):\n",
    "    rng, rng_1, rng_2, rng_3 = jax.random.split(rng, 4)\n",
    "\n",
    "    bs = x_s.shape[0]\n",
    "    z_1 = jax.random.normal(rng_1, shape=(bs, 1, 1, 8))\n",
    "    z_2 = jax.random.normal(rng_2, shape=(bs, 1, 1, 8))\n",
    "    z_3 = jax.random.normal(rng_3, shape=(bs, 1, 1, 8))\n",
    "\n",
    "    c_s, z_s = G_enc().apply({'params': params['g_s_enc']}, x_s)\n",
    "    fake_s = G_dec().apply({'params': params['g_s_dec']}, c_s, z_1)\n",
    "\n",
    "    c_t, z_t = G_enc().apply({'params': params['g_t_enc']}, x_s)\n",
    "    fake_t = G_dec().apply({'params': params['g_t_dec']}, c_t, z_2)\n",
    "\n",
    "    c_recon_s, z_recon_s = G_enc().apply({'params': params['g_s_enc']}, fake_t)\n",
    "    fake_recon_s = G_dec().apply({'params': params['g_s_dec']}, c_recon_s, z_3)\n",
    "\n",
    "    real_logits_s = D().apply({'params': params['d_s']}, x_s)\n",
    "    fake_logits_s = D().apply({'params': params['d_s']}, fake_s)\n",
    "\n",
    "    real_logits_t = D().apply({'params': params['d_t']}, x_t)\n",
    "    fake_logits_t = D().apply({'params': params['d_t']}, fake_t)\n",
    "\n",
    "    real_logits_recon_s = D().apply({'params': params['d_s']}, x_s)\n",
    "    fake_logits_recon_s = D().apply({'params': params['d_s']}, fake_recon_s)\n",
    "\n",
    "    s_fake_s_logits = D().apply({'params': params['d_hat']}, jnp.concatenate([x_s, fake_s], axis=3))\n",
    "    s_fake_recon_s_logits = D().apply({'params': params['d_hat']}, jnp.concatenate([x_s, fake_recon_s], axis=3))\n",
    "\n",
    "    real_adv_labels = [jnp.ones_like(fake_logits_s[0]), jnp.ones_like(fake_logits_s[1]), jnp.ones_like(fake_logits_s[2])]\n",
    "    fake_adv_labels = [jnp.zeros_like(fake_logits_s[0]), jnp.zeros_like(fake_logits_s[1]), jnp.zeros_like(fake_logits_s[2])]\n",
    "    real_acl_labels = [jnp.ones_like(s_fake_s_logits[0]), jnp.ones_like(s_fake_s_logits[1]), jnp.ones_like(s_fake_s_logits[2])]\n",
    "    fake_acl_labels = [jnp.zeros_like(s_fake_s_logits[0]), jnp.zeros_like(s_fake_s_logits[1]), jnp.zeros_like(s_fake_s_logits[2])]\n",
    "\n",
    "    loss_adv = l2_loss(fake_logits_t, fake_adv_labels) + l2_loss(real_logits_t, real_adv_labels) + (l2_loss(fake_logits_s, fake_adv_labels) + l2_loss(real_logits_s, real_adv_labels) + l2_loss(fake_logits_recon_s, fake_adv_labels) + l2_loss(real_logits_recon_s, real_adv_labels)) / 2\n",
    "    loss_acl = l2_loss(s_fake_s_logits, fake_acl_labels) + l2_loss(s_fake_recon_s_logits, real_acl_labels)\n",
    "\n",
    "    loss = loss_adv + 0.5 * loss_acl\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = loss_d(x_s, x_t, rng, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray(7.424428, dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}